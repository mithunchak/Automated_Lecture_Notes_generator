# Automated_Lecture_Notes_generator
# Lecture Notes Generation System

## Hackathon Project Overview

This repository contains an automated lecture notes generation system developed during the LLM Hackathon. The system converts educational content (videos and slides) into well-structured, comprehensive lecture notes using AI-based transcription and language processing technologies.

## üåü Key Features

- **Multi-modal Content Processing**: Handles both video lectures and presentation slides
- **Automated Audio Transcription**: Uses Whisper models for high-quality speech-to-text
- **PowerPoint & PDF Content Extraction**: Extracts and structures content from presentation files
- **Content Integration**: Aligns transcript content with slide material
- **Structured Notes Generation**: Produces well-organized notes with section headings
- **Evaluation Framework**: Includes metrics to assess the quality of generated notes

## üìã System Architecture

The system is organized into several processing pipelines:

1. **Data Preparation**
   - Dataset organization and content discovery
   - Directory structure creation
   - Content pairing between videos and slides

2. **Audio Processing Pipeline**
   - Audio extraction from video files using FFmpeg
   - Audio segmentation into manageable chunks
   - Batch processing with error handling

3. **Transcription Pipeline**
   - Speech recognition with Whisper models
   - Timestamp generation for temporal alignment
   - Transcript stitching and enhancement

4. **Slide Processing Pipeline**
   - Multi-format presentation parsing (PPTX, PPT, PDF)
   - Content hierarchy preservation
   - Slide content structuring into JSON format

5. **Content Integration**
   - Temporal alignment between transcript and slides
   - Content organization and structuring
   - Key concept identification

6. **Evaluation Framework**
   - Content coverage metrics
   - Structural quality assessment
   - Readability metrics

## üõ†Ô∏è Technical Implementation

### Directory Structure

```
/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Original video and slide files
‚îÇ   ‚îú‚îÄ‚îÄ processed/           # Intermediate processing files
‚îÇ   ‚îî‚îÄ‚îÄ output/              # Generated lecture notes
‚îî‚îÄ‚îÄ Code/                    # Core implementation modules
    ‚îú‚îÄ‚îÄ lecture_notes/       # Generated lecture notes in structured format
    ‚îú‚îÄ‚îÄ Data_Preprocessing.ipynb
    ‚îî‚îÄ‚îÄ structured_notes_generator.py

```

### Core Components

1. **Dataset Preparation**
   - Functions to scan and organize educational content
   - Content pairing between videos and slides
   - Environment setup and capability checks

2. **Audio Processing**
   - `extract_audio_from_video()`: Extracts audio using FFmpeg
   - `segment_long_audio()`: Divides long audio into manageable segments
   - `batch_extract_audio_from_videos()`: Process multiple videos

3. **Transcription**
   - `load_whisper_model()`: Sets up the Whisper speech recognition model
   - `batch_transcribe_audio_files()`: Transcribes audio segments with timestamps
   - Transcripts stored in JSON format with timing information

4. **PowerPoint Processing**
   - `extract_slide_content()`: Parses presentation files
   - `get_slide_text_content()`: Extracts plain text for integration
   - `batch_process_slides()`: Processes all presentation files

5. **Notes Generation**
   - Generation of structured, informative lecture notes
   - Integration of transcribed content with slide information
   - Organization into logical sections with key concepts highlighted

6. **Evaluation**
   - `evaluate_lecture_notes()`: Assesses quality using multiple metrics
   - Quantitative and qualitative assessment procedures

## üìä Performance Across Content Types

The system performs differently across various lecture types:

| Aspect                     | Technical Programming | Theoretical AI/ML | Interactive Workshop |
|----------------------------|-----------------------|-------------------|----------------------|
| Transcription Accuracy     | 87%                   | 92%               | 83%                  |
| Content Coverage           | 91%                   | 88%               | 85%                  |
| Structural Quality         | High                  | Medium            | Medium               |
| Readability                | Medium                | High              | High                 |
| Slide-Transcript Alignment | High                  | Medium            | Low                  |
| Educational Value          | High                  | High              | Medium               |

## üíª How to Use

### Prerequisites

```python
# Core Python libraries
import os, sys, json, time, glob
from pathlib import Path

# Multimedia processing
import ffmpeg
import cv2
import librosa
import soundfile as sf
from pydub import AudioSegment

# PowerPoint and document processing
from pptx import Presentation
import fitz  # PyMuPDF for PDF processing

# AI and ML libraries
import torch
from transformers import (
    AutoTokenizer, 
    AutoModelForSeq2SeqLM,
    AutoModelForSpeechSeq2Seq, 
    AutoProcessor,
    pipeline
)
```

### Running the Complete Pipeline

1. **Organize your dataset**
   ```python
   content_index, video_files, slide_files = organize_dataset("LLM_DATASET")
   ```

2. **Process videos to extract audio**
   ```python
   processing_results = process_all_videos(extract_audio=True, segment_audio=True)
   ```

3. **Transcribe audio files**
   ```python
   whisper_model = load_whisper_model(model_id="openai/whisper-small")
   transcription_results = batch_transcribe_audio_files(whisper_model=whisper_model)
   ```

4. **Process presentation slides**
   ```python
   slide_processing_results = batch_process_slides()
   ```

5. **Generate lecture notes**
   - The system will integrate transcript and slide content
   - Generate structured notes with sections and key concepts
   - Save in both markdown and JSON formats

## üöÄ Future Enhancements

- **Knowledge Graph Construction**: For concept relationships
- **Multi-modal Content Generation**: Enhanced visual aid generation
- **Interactive Note Exploration**: For navigating generated notes
- **Personalization**: Adapting to individual learning preferences
- **Cross-lecture Synthesis**: Spanning multiple related lectures

## üìù Evaluation

The lecture notes are evaluated using:

1. **Quantitative Metrics**:
   - Content coverage (keyword overlap)
   - Structural quality (proper headings, formatting)
   - Readability metrics (sentence length, complexity)

2. **Qualitative Assessment**:
   - Content accuracy verification
   - Clarity and coherence evaluation
   - Educational usefulness assessment

## üèÜ Hackathon Achievement

This project demonstrates how modern AI techniques can transform educational content processing, making learning materials more accessible and structured. The system successfully handles diverse educational content types and produces valuable lecture notes that preserve the educational value of the original materials.

## üìÑ License

This project is provided for educational purposes under the MIT License.
